{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74e2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mohd Uvas 18BCS079\n",
    "# B.Tech(Computer Engineering 2018-2022 )\n",
    "# Semester 8\n",
    "\n",
    "#Problem:-\n",
    "#Implement the Byte pair Encoding Algorithm of tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea95db",
   "metadata": {},
   "source": [
    "# Getting the rules using training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610a0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking file as input and returning vocabulary \n",
    "def get_vocab(text):\n",
    "\n",
    "    text = text.replace('\\n','')\n",
    "    text=text.split()\n",
    "    print(text)\n",
    "    token_count=dict()\n",
    "    \n",
    "    for x in text:\n",
    "        if x[-1]==',' or x[-1]=='.':\n",
    "            x=x[:-1]\n",
    "\n",
    "        x+='_'\n",
    "        \n",
    "        x_n=''\n",
    "        for ch in x:\n",
    "            x_n=x_n+ch+' '\n",
    "        x=x_n[:-1]\n",
    "        \n",
    "        if x in token_count:\n",
    "            token_count[x]+=1\n",
    "        else:\n",
    "            token_count[x]=1\n",
    "            \n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9372449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking vocab as input and returning list of pair with thier frequency \n",
    "def get_pair_stats(vocab):\n",
    "    pairs=dict()\n",
    "    for word,frequency in vocab.items():\n",
    "        symbols=word.split()\n",
    "        \n",
    "        for i in range(len(symbols)-1):\n",
    "            pair=(symbols[i],symbols[i+1])\n",
    "            current_frequency = pairs.get(pair,0)\n",
    "            pairs[pair]=current_frequency+frequency\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9750203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking pair to be merged and vocabulary as input and returning merged pair vocabulary\n",
    "def merge_vocab(best_pair,vocab_in):\n",
    "    vocab_out=dict()\n",
    "    pattern = ' '.join(best_pair)\n",
    "    replacement = ''.join(best_pair)\n",
    "    for vb in vocab_in:\n",
    "        vb_temp=vb\n",
    "        if pattern in vb:\n",
    "            vb=vb.replace(pattern,replacement)\n",
    "            \n",
    "        vocab_out[vb]=vocab_in[vb_temp]\n",
    "        \n",
    "    return vocab_out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ce44d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['old', 'faster', 'older', 'old', 'older', 'finest.', 'faster', 'old', 'older', 'lowest', 'finest.', 'old', 'finest.', 'old', 'faster', 'faster', 'faster', 'faster', 'finest.', 'old', 'lowest', 'finest.', 'finest.', 'faster', 'lowest', 'old', 'finest.', 'finest.', 'finest.', 'lowest.', 'faster']\n",
      "{'o l d _': 7, 'f a s t e r _': 8, 'o l d e r _': 3, 'f i n e s t _': 9, 'l o w e s t _': 4}\n",
      "\n",
      "iteration 0\n",
      "vocabulary:  {'o l d _': 7, 'f a s t e r _': 8, 'o l d e r _': 3, 'f i n e s t _': 9, 'l o w e s t _': 4}\n",
      "best pair: ('s', 't')\n",
      "\n",
      "iteration 1\n",
      "vocabulary:  {'o l d _': 7, 'f a st e r _': 8, 'o l d e r _': 3, 'f i n e st _': 9, 'l o w e st _': 4}\n",
      "best pair: ('e', 'st')\n",
      "\n",
      "iteration 2\n",
      "vocabulary:  {'o l d _': 7, 'f a st e r _': 8, 'o l d e r _': 3, 'f i n est _': 9, 'l o w est _': 4}\n",
      "best pair: ('est', '_')\n",
      "\n",
      "iteration 3\n",
      "vocabulary:  {'o l d _': 7, 'f a st e r _': 8, 'o l d e r _': 3, 'f i n est_': 9, 'l o w est_': 4}\n",
      "best pair: ('e', 'r')\n",
      "\n",
      "iteration 4\n",
      "vocabulary:  {'o l d _': 7, 'f a st er _': 8, 'o l d er _': 3, 'f i n est_': 9, 'l o w est_': 4}\n",
      "best pair: ('er', '_')\n",
      "\n",
      "iteration 5\n",
      "vocabulary:  {'o l d _': 7, 'f a st er_': 8, 'o l d er_': 3, 'f i n est_': 9, 'l o w est_': 4}\n",
      "best pair: ('o', 'l')\n",
      "\n",
      "iteration 6\n",
      "vocabulary:  {'ol d _': 7, 'f a st er_': 8, 'ol d er_': 3, 'f i n est_': 9, 'l o w est_': 4}\n",
      "best pair: ('ol', 'd')\n",
      "\n",
      "iteration 7\n",
      "vocabulary:  {'old _': 7, 'f a st er_': 8, 'old er_': 3, 'f i n est_': 9, 'l o w est_': 4}\n",
      "best pair: ('f', 'i')\n",
      "\n",
      "iteration 8\n",
      "vocabulary:  {'old _': 7, 'f a st er_': 8, 'old er_': 3, 'fi n est_': 9, 'l o w est_': 4}\n",
      "best pair: ('fi', 'n')\n",
      "\n",
      "iteration 9\n",
      "vocabulary:  {'old _': 7, 'f a st er_': 8, 'old er_': 3, 'fin est_': 9, 'l o w est_': 4}\n",
      "best pair: ('fin', 'est_')\n",
      "\n",
      "iteration 10\n",
      "vocabulary:  {'old _': 7, 'f a st er_': 8, 'old er_': 3, 'finest_': 9, 'l o w est_': 4}\n",
      "best pair: ('f', 'a')\n",
      "\n",
      "iteration 11\n",
      "vocabulary:  {'old _': 7, 'fa st er_': 8, 'old er_': 3, 'finest_': 9, 'l o w est_': 4}\n",
      "best pair: ('fa', 'st')\n",
      "\n",
      "iteration 12\n",
      "vocabulary:  {'old _': 7, 'fast er_': 8, 'old er_': 3, 'finest_': 9, 'l o w est_': 4}\n",
      "best pair: ('fast', 'er_')\n",
      "\n",
      "iteration 13\n",
      "vocabulary:  {'old _': 7, 'faster_': 8, 'old er_': 3, 'finest_': 9, 'l o w est_': 4}\n",
      "best pair: ('old', '_')\n",
      "\n",
      "iteration 14\n",
      "vocabulary:  {'old_': 7, 'faster_': 8, 'old er_': 3, 'finest_': 9, 'l o w est_': 4}\n",
      "best pair: ('l', 'o')\n",
      "\n",
      "iteration 15\n",
      "vocabulary:  {'old_': 7, 'faster_': 8, 'old er_': 3, 'finest_': 9, 'lo w est_': 4}\n",
      "best pair: ('lo', 'w')\n",
      "\n",
      "iteration 16\n",
      "vocabulary:  {'old_': 7, 'faster_': 8, 'old er_': 3, 'finest_': 9, 'low est_': 4}\n",
      "best pair: ('low', 'est_')\n",
      "\n",
      "iteration 17\n",
      "vocabulary:  {'old_': 7, 'faster_': 8, 'old er_': 3, 'finest_': 9, 'lowest_': 4}\n",
      "best pair: ('old', 'er_')\n",
      "\n",
      "iteration 18\n",
      "\n",
      "final vocabulary:  {'old_': 7, 'faster_': 8, 'older_': 3, 'finest_': 9, 'lowest_': 4} 5\n",
      "\n",
      "byte pair encoding:  {('s', 't'): 0, ('e', 'st'): 1, ('est', '_'): 2, ('e', 'r'): 3, ('er', '_'): 4, ('o', 'l'): 5, ('ol', 'd'): 6, ('f', 'i'): 7, ('fi', 'n'): 8, ('fin', 'est_'): 9, ('f', 'a'): 10, ('fa', 'st'): 11, ('fast', 'er_'): 12, ('old', '_'): 13, ('l', 'o'): 14, ('lo', 'w'): 15, ('low', 'est_'): 16, ('old', 'er_'): 17}\n"
     ]
    }
   ],
   "source": [
    "#program for generating rules for merging \n",
    "\n",
    "file = open('train_data.txt')\n",
    "text = file.read()\n",
    "vocab = get_vocab(text)\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "bpe_codes = dict()\n",
    "num_merges = 20 \n",
    "for i in range(num_merges):\n",
    "    print('\\niteration', i)\n",
    "    pair_stats = get_pair_stats(vocab)\n",
    "    if not pair_stats:\n",
    "        break\n",
    "\n",
    "    best_pair = max(pair_stats, key=pair_stats.get)\n",
    "    bpe_codes[best_pair] = i\n",
    "\n",
    "    print('vocabulary: ', vocab)\n",
    "    print('best pair:', best_pair)\n",
    "    vocab = merge_vocab(best_pair, vocab)\n",
    "\n",
    "print('\\nfinal vocabulary: ', vocab,len(vocab))\n",
    "print('\\nbyte pair encoding: ', bpe_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d4cf0",
   "metadata": {},
   "source": [
    "# Applying them on testing corpus for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172b2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting possible pairs for a list of character or string\n",
    "def get_pairs(word):\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d8cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new word after merging the pair into string\n",
    "def create_new_word(word, pair_to_merge):\n",
    "    first, second = pair_to_merge\n",
    "    new_word = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        try:\n",
    "            j = word.index(first, i)\n",
    "            new_word.extend(word[i:j])\n",
    "            i = j\n",
    "        except ValueError:\n",
    "            new_word.extend(word[i:])\n",
    "            break\n",
    "\n",
    "        if i < len(word) - 1 and word[i + 1] == second:\n",
    "            new_word.append(first + second)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_word.append(first)\n",
    "            i += 1\n",
    "\n",
    "    return new_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dade864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the characters or string till no pair matching in byte pair\n",
    "def encode(original_word, bpe_codes):\n",
    "    if len(original_word) == 1:\n",
    "        return original_word\n",
    "\n",
    "    word = list(original_word)\n",
    "    word.append('_')\n",
    "    \n",
    "    while True:\n",
    "        pairs = get_pairs(word)\n",
    "        bpe_codes_pairs = [(pair, bpe_codes[pair]) for pair in pairs if pair in bpe_codes]\n",
    "        if not bpe_codes_pairs:\n",
    "            break\n",
    "            \n",
    "        min_ptm=9999\n",
    "        for pair in bpe_codes_pairs:\n",
    "            if pair[1]<min_ptm:\n",
    "                min_ptm=pair[1]\n",
    "                pair_to_merge=pair[0]\n",
    "                \n",
    "        word = create_new_word(word, pair_to_merge)\n",
    "\n",
    "        \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ab387b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking read file as input returning vocab without space \n",
    "def get_vocab_test(text_1):\n",
    "    \n",
    "    text_1 = text_1.replace('\\n','')\n",
    "    text_1=text_1.split()\n",
    "    \n",
    "    token_count_test=dict()\n",
    "    \n",
    "    for x in text_1:\n",
    "        if x[-1]==',' or x[-1]=='.':\n",
    "            x=x[:-1]\n",
    "            x+='_'\n",
    "\n",
    "        else:\n",
    "            x+='_'\n",
    "        \n",
    "        if x in token_count_test:\n",
    "            token_count_test[x]+=1\n",
    "        else:\n",
    "            token_count_test[x]=1\n",
    "            \n",
    "    return token_count_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a71b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_vocab\n",
      " {'oldest_': 7, 'finer_': 5, 'lower_': 5, 'lowest_': 5, 'fastest_': 5, 'finold_': 1, 'faster_': 5, 'finest_': 5, 'older_': 6} 9\n",
      "\n",
      "\n",
      "\n",
      "new_vocab\n",
      " {'lowest_': 5, 'faster_': 5, 'finest_': 5, 'older_': 6, 'old': 7, 'est_': 12, 'fin': 6, 'er_': 10, 'low': 5, 'fast': 5, 'old_': 1} 11\n"
     ]
    }
   ],
   "source": [
    "#opening test data file and tokenizing word\n",
    "file_test = open('test_data.txt')\n",
    "text_test = file_test.read()\n",
    "vocab_test = get_vocab_test(text_test)\n",
    "\n",
    "print(\"old_vocab\\n\",vocab_test,len(vocab_test))\n",
    "\n",
    "static_vocab_test=[]\n",
    "for st in vocab_test:\n",
    "    static_vocab_test.append(st)\n",
    "    \n",
    "for oe_word in static_vocab_test:\n",
    "    oe_word_temp=oe_word\n",
    "    oe_word=oe_word[:-1]\n",
    "    \n",
    "    if len(oe_word)>2:\n",
    "        oe_word_list=encode(oe_word, bpe_codes)\n",
    "        if (len(oe_word_list)==2) and (len(oe_word_list[-1]) != 1):\n",
    "            \n",
    "            if oe_word_list[0] in vocab_test:\n",
    "                vocab_test[oe_word_list[0]]+=vocab_test[oe_word_temp]\n",
    "            else:\n",
    "                vocab_test[oe_word_list[0]]=vocab_test[oe_word_temp]\n",
    "            \n",
    "            if oe_word_list[1] in vocab_test:\n",
    "                vocab_test[oe_word_list[1]]+=vocab_test[oe_word_temp]\n",
    "            else:\n",
    "                vocab_test[oe_word_list[1]]=vocab_test[oe_word_temp]\n",
    "            \n",
    "            del vocab_test[oe_word_temp]\n",
    "\n",
    "print(\"\\n\\n\\nnew_vocab\\n\",vocab_test,len(vocab_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
